<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: eclairjs/SparkContext.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: eclairjs/SparkContext.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/*
 * Copyright 2015 IBM Corp.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

(function () {

    var JavaWrapper = require(EclairJS_Globals.NAMESPACE + '/JavaWrapper');
    var Logger = require(EclairJS_Globals.NAMESPACE + '/Logger');
    var Utils = require(EclairJS_Globals.NAMESPACE + '/Utils');
    var SparkConf = require(EclairJS_Globals.NAMESPACE + '/SparkConf');

    var initSparkContext = function (conf) {
        var logger = Logger.getLogger("SparkContext_js");
        if (typeof kernel !== 'undefined') {
            if (kernel.javaSparkContext() != null) {
                return kernel.javaSparkContext();
            } else {
                kernel.createSparkContext(Utils.unwrapObject(conf));
                return kernel.javaSparkContext();
            }
        }

        /*
         * Create a new JavaSparkContext from a conf
         *
         */
        var jvmSC = new org.apache.spark.api.java.JavaSparkContext(Utils.unwrapObject(conf));
        /*
         * add the jar for the cluster
         */
        var decodedPath = org.eclairjs.nashorn.Utils.jarLoc();
        var devEnvPath = "/target/classes/";
        var jarEnvPath = ".jar";
        logger.info("jar decodedPath = " + decodedPath);
        if (decodedPath.indexOf(devEnvPath,
                decodedPath.length - devEnvPath.length) !== -1) {
            /*
             * we are in the dev environment I hope...
             */
            jvmSC.addJar(decodedPath + "../eclairjs-nashorn-0.1.jar");
        } else if (decodedPath.indexOf(jarEnvPath,
                decodedPath.length - jarEnvPath.length) !== -1) {
            /*
             * We are running from a jar
             */
            jvmSC.addJar(decodedPath);
        }

        return jvmSC
    };
    /**
     *
     * @constructor
     * @memberof module:eclairjs
     * @classdesc A JavaScript-friendly version of SparkContext that returns RDDs
     * Only one SparkContext may be active per JVM. You must stop() the active SparkContext before creating a new one.
     * This limitation may eventually be removed; see SPARK-2243 for more details.
     * @param {SparkConf} conf - a object specifying Spark parameters
     */
    var SparkContext = function () {
        var jvmObj;
        this.logger = Logger.getLogger("SparkContext_js");
        if (arguments.length == 2) {
            var conf = new SparkConf()
            conf.setMaster(arguments[0])
            conf.setAppName(arguments[1])
            jvmObj = initSparkContext(conf)
        } else if (arguments.length == 1 &amp;&amp;
            (arguments[0] instanceof org.apache.spark.api.java.JavaSparkContext)) {
            jvmObj = arguments[0];
        } else {
            jvmObj = initSparkContext(arguments[0])
        }
        JavaWrapper.call(this, jvmObj);
        this.logger.debug(this.version());
    };

    SparkContext.prototype = Object.create(JavaWrapper.prototype);

//Set the "constructor" property to refer to SparkContext
    SparkContext.prototype.constructor = SparkContext;

    /**
     * Return a copy of this SparkContext's configuration. The configuration ''cannot'' be
     * changed at runtime.
     * @returns {SparkConf}
     */
    SparkContext.prototype.getConf = function () {
        var javaObject = this.getJavaObject().getConf();
        return new SparkConf(javaObject);
    };


    /**
     * @returns {string[]}
     */
    SparkContext.prototype.jars = function () {
        return this.getJavaObject().jars();
    };


    /**
     * @returns {string[]}
     */
    SparkContext.prototype.files = function () {
        return this.getJavaObject().files();
    };


    /**
     * @returns {string}
     */
    SparkContext.prototype.master = function () {
        return this.getJavaObject().master();
    };


    /**
     * @returns {string}
     */
    SparkContext.prototype.appName = function () {
        return this.getJavaObject().appName();
    };


    /**
     * @returns {boolean}
     */
    SparkContext.prototype.isLocal = function () {
        return this.getJavaObject().isLocal();
    };

    /**
     * @returns {boolean}  true if context is stopped or in the midst of stopping.
     */
    SparkContext.prototype.isStopped = function () {
        return this.getJavaObject().isStopped();
    };


    /**
     * @returns {SparkStatusTracker}
     */
    SparkContext.prototype.statusTracker = function () {
        var javaObject = this.getJavaObject().statusTracker();
        return Utils.javaToJs(javaObject);
    };

    /**
     * A unique identifier for the Spark application.
     * Its format depends on the scheduler implementation.
     * (i.e.
     *  in case of local spark app something like 'local-1433865536131'
     *  in case of YARN something like 'application_1433865536131_34483'
     * )
     * @returns {string}
     */
    SparkContext.prototype.applicationId = function () {
        return this.getJavaObject().applicationId();
    };


    /**
     * @returns {string}
     */
    SparkContext.prototype.applicationAttemptId = function () {
        return this.getJavaObject().applicationAttemptId();
    };


    /**
     * @param {string} logLevel  The desired log level as a string.
     * Valid log levels include: ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN
     */
    SparkContext.prototype.setLogLevel = function (logLevel) {
        this.getJavaObject().setLogLevel(logLevel);
    };


    /**
     * initLocalProperties
     */
    SparkContext.prototype.initLocalProperties = function () {
        this.getJavaObject().initLocalProperties();
    };


    /**
     * Set a local property that affects jobs submitted from this thread, such as the
     * Spark fair scheduler pool.
     * @param {string}
     * @param {string}
     */
    SparkContext.prototype.setLocalProperty = function (key, value) {
        this.getJavaObject().setLocalProperty(key, value);
    };


    /**
     * Get a local property set in this thread, or null if it is missing. See
     * {@link setLocalProperty}.
     * @param {string}
     * @returns {string}
     */
    SparkContext.prototype.getLocalProperty = function (key) {
        return this.getJavaObject().getLocalProperty(key);
    };


    /**
     * @param {string}
     */
    SparkContext.prototype.setJobDescription = function (value) {
        this.getJavaObject().setJobDescription(value);
    };


    /**
     * Assigns a group ID to all the jobs started by this thread until the group ID is set to a
     * different value or cleared.
     *
     * Often, a unit of execution in an application consists of multiple Spark actions or jobs.
     * Application programmers can use this method to group all those jobs together and give a
     * group description. Once set, the Spark web UI will associate such jobs with this group.
     *
     * The application can also use {@link cancelJobGroup} to cancel all
     * running jobs in this group. For example,
     * @param {string}
     * @param {string}
     * @param {boolean}
     */
    SparkContext.prototype.setJobGroup = function (groupId, description, interruptOnCancel) {
        this.getJavaObject().setJobGroup(groupId, description, interruptOnCancel);
    };


    /**
     * clearJobGroup
     */
    SparkContext.prototype.clearJobGroup = function () {
        this.getJavaObject().clearJobGroup();
    };


    /**
     * Create an {@link Accumulable} shared variable of the given type, to which tasks can "add" values with add.
     * Only the master can access the accumuable's value.
     *
     * @param {object} initialValue
     * @param {AccumulableParam} param
     * @param {string} name of  the accumulator for display in Spark's web UI.
     * @returns {Accumulable}
     */
    SparkContext.prototype.accumulable = function (initialValue, param, name) {
        var Accumulable = require(EclairJS_Globals.NAMESPACE + '/Accumulable');
        return new Accumulable(initialValue, param, name);

    };
    /**
     * Create an {@link Accumulator}  variable, which tasks can "add" values to using the add method.
     * Only the master can access the accumulator's value.
     *
     * @param {int | float} initialValue
     * @param {string | AccumulableParam} [name] of  the accumulator for display in Spark's web UI. or param.  defaults to FloatAccumulatorParam
     * @param {AccumulableParam} [param]  defaults to FloatAccumulatorParam, use only if also specifying name
     * @returns {Accumulator}
     */
    SparkContext.prototype.accumulator = function () {
        var Accumulator = require(EclairJS_Globals.NAMESPACE + '/Accumulator');
        var FloatAccumulatorParam = require(EclairJS_Globals.NAMESPACE + '/FloatAccumulatorParam');

        var initialValue = arguments[0];
        var name;
        var param = new FloatAccumulatorParam();
        this.logger.debug("accumulator " + initialValue);

        if (arguments[1]) {
            if (typeof arguments[1] === "string") {
                name = arguments[1];
                if (arguments[2]) {
                    param = arguments[2];
                }
            } else {
                param = arguments[1];
            }
        }
        return new Accumulator(initialValue, param, name);

    };
    /**
     * Create an Accumulator integer variable, which tasks can "add" values to using the add method.
     * Only the master can access the accumulator's value.
     * @param {int} initialValue
     * @param {string} name of  the accumulator for display in Spark's web UI.
     * @returns {Accumulator}
     */
    SparkContext.prototype.intAccumulator = function (initialValue, name) {
        var Accumulator = require(EclairJS_Globals.NAMESPACE + '/Accumulator');
        var IntAccumulatorParam = require(EclairJS_Globals.NAMESPACE + '/IntAccumulatorParam');

        return new Accumulator(initialValue, new IntAccumulatorParam(), name);

    };
    /**
     * Create an Accumulator float variable, which tasks can "add" values to using the add method.
     * Only the master can access the accumulator's value.
     * @param {float} initialValue
     * @param {string} name of  the accumulator for display in Spark's web UI.
     * @returns {Accumulator}
     */
    SparkContext.prototype.floatAccumulator = function (initialValue, name) {
        var Accumulator = require(EclairJS_Globals.NAMESPACE + '/Accumulator');
        var FloatAccumulatorParam = require(EclairJS_Globals.NAMESPACE + '/FloatAccumulatorParam');
        return new Accumulator(initialValue, new FloatAccumulatorParam(), name);

    };
    /**
     *  Add a file to be downloaded with this Spark job on every node. The path passed can be either a local file,
     * a file in HDFS (or other Hadoop-supported filesystems), or an HTTP, HTTPS or FTP URI.
     * To access the file in Spark jobs, use SparkFiles.get(fileName) to find its download location.
     * @param {string} path - Path to the file
     */
    SparkContext.prototype.addFile = function (path) {
        this.getJavaObject().addFile(path);
    };
    /**
     * Adds a JAR dependency for all tasks to be executed on this SparkContext in the future. The path passed can be either a local file, a file in HDFS (or other Hadoop-supported filesystems), or an HTTP, HTTPS or FTP URI.
     * @param {string} path - Path to the jar
     */
    SparkContext.prototype.addJar = function (path) {
        //public void addJar(java.lang.String path)
        this.getJavaObject().addJar(path);
    };
    /**
     * Broadcast a read-only variable to the cluster, returning a Broadcast object for reading it in distributed functions.
     * The variable will be sent to each cluster only once.
     * @param {object} value
     * @returns {Broadcast}
     */
    SparkContext.prototype.broadcast = function (value) {
        return this.getJavaObject().broadcast(value);
    };

    /**
     * Distribute a local Scala collection to form an RDD.
     * @param {array} list
     * @param {integer} [numSlices]
     * @returns {RDD}
     */
    SparkContext.prototype.parallelize = function (list, numSlices) {
        //public &lt;T> JavaRDD&lt;T> parallelize(java.util.List&lt;T> list, int numSlices)
        var list_uw = [];
        list.forEach(function (item) {
            list_uw.push(Utils.unwrapObject(item));
            //list_uw.push(Serialize.jsToJava(item));
        });
        if (numSlices) {
            return  Utils.javaToJs(this.getJavaObject().parallelize(list_uw, numSlices));
        } else {
            return  Utils.javaToJs(this.getJavaObject().parallelize(list_uw));
        }

    };


    /**
     * Distribute a local collection to form an RDD.
     * @param {array} list array of Tuple 2
     * @param {integer} numSlices
     * @returns {PairRDD}
     */
    SparkContext.prototype.parallelizePairs = function (list, numSlices) {
        //public &lt;T> JavaRDD&lt;T> parallelize(java.util.List&lt;T> list, int numSlices)
        var list_uw = [];
        list.forEach(function (item) {
            list_uw.push(Utils.unwrapObject(item));
        });
        if (numSlices) {
            return Utils.javaToJs(this.getJavaObject().parallelizePairs(list_uw, numSlices));
        } else {
            return Utils.javaToJs(this.getJavaObject().parallelizePairs(list_uw));
        }

    };
    /**
     * Creates a new RDD[Long] containing elements from `start` to `end`(exclusive), increased by
     * `step` every element.
     *
     * @note if we need to cache this RDD, we should make sure each partition does not exceed limit.
     *
     * @param {number} start  the start value.
     * @param {number} end  the end value.
     * @param {number} step  the incremental step
     * @param {number} numSlices  the partition number of the new RDD.
     * @returns {RDD}
     */
    SparkContext.prototype.range = function (start, end, step, numSlices) {
        var javaObject = this.getJavaObject().range(start, end, step, numSlices);
        return new Utils.javaToJs(javaObject);
    };


    /**
     * Read a text file from HDFS, a local file system (available on all nodes), or any Hadoop-supported file system URI,
     * and return it as an RDD of Strings.
     * @param {string} path - path to file
     * @param {int} [minPartitions]
     * @returns {RDD}
     */
    SparkContext.prototype.textFile = function (path, minPartitions) {
        if (minPartitions) {
            return Utils.javaToJs(this.getJavaObject().textFile(path, minPartitions));
        } else {
            return Utils.javaToJs(this.getJavaObject().textFile(path));
        }

    };


    /**
     * Read a directory of text files from HDFS, a local file system (available on all nodes), or any
     * Hadoop-supported file system URI. Each file is read as a single record and returned in a
     * key-value pair, where the key is the path of each file, the value is the content of each file.
     *
     * &lt;p> For example, if you have the following files:
     * @example
     *   hdfs://a-hdfs-path/part-00000
     *   hdfs://a-hdfs-path/part-00001
     *   ...
     *   hdfs://a-hdfs-path/part-nnnnn
     *
     *
     * Do `var rdd = sparkContext.wholeTextFile("hdfs://a-hdfs-path")`,
     *
     * &lt;p> then `rdd` contains
     * @example
     *   (a-hdfs-path/part-00000, its content)
     *   (a-hdfs-path/part-00001, its content)
     *   ...
     *   (a-hdfs-path/part-nnnnn, its content)
     *
     *
     * @note Small files are preferred, large file is also allowable, but may cause bad performance.
     * @note On some filesystems, `.../path/&amp;#42;` can be a more efficient way to read all files
     *       in a directory rather than `.../path/` or `.../path`
     *
     * @param {string} path  Directory to the input data files, the path can be comma separated paths as the
     *             list of inputs.
     * @param {number} minPartitions  A suggestion value of the minimal splitting number for input data.
     * @returns {RDD}
     */
    SparkContext.prototype.wholeTextFiles = function (path, minPartitions) {
        var javaObject = this.getJavaObject().wholeTextFiles(path, minPartitions);
        return  Utils.javaToJs(javaObject);
    };

    /**
     * Set the directory under which RDDs are going to be checkpointed.
     * The directory must be a HDFS path if running on a cluster.
     * @param {string} dir
     */
    SparkContext.prototype.setCheckpointDir = function (dir) {
        this.getJavaObject().setCheckpointDir(dir);
    };

    /**
     * Shut down the SparkContext.
     */
    SparkContext.prototype.stop = function () {
        this.getJavaObject().stop();
    };

    /**
     * The version of EclairJS and Spark on which this application is running.
     * @returns {string}
     */
    SparkContext.prototype.version = function () {
        var javaVersion = java.lang.System.getProperty("java.version");
        var jv = javaVersion.split(".");
        var wrongJavaVersionString = "Java 1.8.0_60 or greater required for EclairJS";
        var wrongSparkVersionString = "Spark 1.5.1 or greater required for EclairJS";
        if (jv[0] &lt; 2) {
            if (jv[0] == 1) {
                if (jv[1] &lt; 8) {
                    throw wrongJavaVersionString;
                } else {
                    if (jv[1] == 8) {
                        // we are at 1.8
                        var f = jv[2]
                        var fix = f.split("_");
                        if ((fix[0] &lt; 1) &amp;&amp; (fix[1] &lt; 60)) {
                            // less than 1.8.0_60
                            throw wrongJavaVersionString;
                        }
                    } else {
                        // 1.9 or greater
                    }
                }
            } else {
                throw wrongJavaVersionString;
            }

        } else {
            // versions is 2.0 or greater
        }
        var sparkVersion = this.getJavaObject().version();
        var sv = sparkVersion.split(".");
        if (sv[0] &lt; 2) {
            if (sv[0] == 1) {
                if (sv[1] &lt; 5) {
                    throw wrongSparkVersionString;
                } else {
                    if (sv[1] == 5) {
                        // we are at 1.5
                        if (sv[2] &lt; 1) {
                            // less than 1.5.1
                            throw wrongSparkVersionString;
                        }
                    } else {
                        // 1.5 or greater
                    }
                }
            } else {
                throw wrongSparkVersionString;
            }

        } else {
            // versions is 2.0 or greater
        }
        return "EclairJS-nashorn 0.1 Spark " + sparkVersion;
    };

    /**
     * Zip up a file in a directory to preserve it's path and add it to worker node for download via addFile.
     */
    SparkContext.prototype.addModule = function (module) {
        //print("SparkContext.addModule: "+module.toString());
        //var folder = module.modname.slice(0, module.modname.lastIndexOf("\/")),
        var parent = ModuleUtils.getParent(module);
        //print("SparkContext.addModule parent: "+parent);

        var folder = (parent &amp;&amp; parent.subdir &amp;&amp; module.subdir.indexOf(parent.subdir) > -1) ? parent.subdir : (module.subdir || "."),
            zipfile = parent &amp;&amp; parent.zipfile ? parent.zipfile.replace(".zip", "_child_" + Date.now() + ".zip") : "module_" + Date.now() + ".zip",
            filename = module.id.slice(module.id.lastIndexOf("\/") + 1, module.id.length);
        //print("SparkContext.addModule folder: "+folder);
        //print("SparkContext.addModule filename: "+filename);
        try {
            org.eclairjs.nashorn.Utils.zipFile(folder, zipfile, [filename]);
            //print("SparkContext.addModule zipped file now going to try and addFile: "+zipfile);
            this.getJavaObject().addFile(zipfile);
            module.zipfile = zipfile;
        } catch (exc) {
            print("Cannot add module: " + module.modname);
            print(exc);
        }
    };

    /**
     * Zip up all required files not in JAR to preserve paths and add it to worker node for download via addFile.
     */
    SparkContext.prototype.addCustomModules = function () {
        var mods = ModuleUtils.getModulesByType({type: "core", value: false});
        //print("addingCustomMods: "+mods.toString());
        var folder = ".", zipfile = ModuleUtils.defaultZipFile, filenames = [];
        mods.forEach(function (mod) {
            filenames.push(mod.id.slice(mod.id.lastIndexOf("\/") + 1, mod.id.length));
        });
        //print("SparkContext.addModule folder: "+folder);
        //print("SparkContext.addModule filenames: "+filenames.toString());
        try {
            org.eclairjs.nashorn.Utils.zipFile(folder, zipfile, filenames);
            this.getJavaObject().addFile(zipfile);
        } catch (exc) {
            print("Cannot add non core modules: " + filenames.toString());
            print(exc);
        }
    };

    module.exports = SparkContext;


})();</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Modules</h3><ul><li><a href="module-eclairjs.html">eclairjs</a></li><li><a href="module-eclairjs_ml_feature.html">eclairjs/ml/feature</a></li><li><a href="module-eclairjs_mllib.html">eclairjs/mllib</a></li><li><a href="module-eclairjs_mllib_classification.html">eclairjs/mllib/classification</a></li><li><a href="module-eclairjs_mllib_clustering.html">eclairjs/mllib/clustering</a></li><li><a href="module-eclairjs_mllib_evaluation.html">eclairjs/mllib/evaluation</a></li><li><a href="module-eclairjs_mllib_feature.html">eclairjs/mllib/feature</a></li><li><a href="module-eclairjs_mllib_fpm.html">eclairjs/mllib/fpm</a></li><li><a href="module-eclairjs_mllib_linalg.html">eclairjs/mllib/linalg</a></li><li><a href="module-eclairjs_mllib_linalg_distributed.html">eclairjs/mllib/linalg/distributed</a></li><li><a href="module-eclairjs_mllib_optimization.html">eclairjs/mllib/optimization</a></li><li><a href="module-eclairjs_mllib_random.html">eclairjs/mllib/random</a></li><li><a href="module-eclairjs_mllib_recommendation.html">eclairjs/mllib/recommendation</a></li><li><a href="module-eclairjs_mllib_regression.html">eclairjs/mllib/regression</a></li><li><a href="module-eclairjs_mllib_tree.html">eclairjs/mllib/tree</a></li><li><a href="module-eclairjs_mllib_tree_configuration.html">eclairjs/mllib/tree/configuration</a></li><li><a href="module-eclairjs_mllib_tree_loss.html">eclairjs/mllib/tree/loss</a></li><li><a href="module-eclairjs_mllib_tree_model.html">eclairjs/mllib/tree/model</a></li><li><a href="module-eclairjs_sql.html">eclairjs/sql</a></li><li><a href="module-eclairjs_sql_execution.html">eclairjs/sql/execution</a></li><li><a href="module-eclairjs_sql_types.html">eclairjs/sql/types</a></li><li><a href="module-eclairjs_storage.html">eclairjs/storage</a></li><li><a href="module-eclairjs_streaming.html">eclairjs/streaming</a></li><li><a href="module-eclairjs_streaming_dstream.html">eclairjs/streaming/dstream</a></li><li><a href="module-eclairjs_streaming_kafka.html">eclairjs/streaming/kafka</a></li><li><a href="module-eclairjs_streaming_twitter.html">eclairjs/streaming/twitter</a></li></ul><h3>Classes</h3><ul><li><a href="module-eclairjs.Accumulable.html">Accumulable</a></li><li><a href="module-eclairjs.AccumulableParam.html">AccumulableParam</a></li><li><a href="module-eclairjs.Accumulator.html">Accumulator</a></li><li><a href="module-eclairjs.FloatAccumulatorParam.html">FloatAccumulatorParam</a></li><li><a href="module-eclairjs.FloatRDD.html">FloatRDD</a></li><li><a href="module-eclairjs.FutureAction.html">FutureAction</a></li><li><a href="module-eclairjs.HashPartitioner.html">HashPartitioner</a></li><li><a href="module-eclairjs.IntAccumulatorParam.html">IntAccumulatorParam</a></li><li><a href="module-eclairjs.List.html">List</a></li><li><a href="module-eclairjs.Logger.html">Logger</a></li><li><a href="module-eclairjs.PairRDD.html">PairRDD</a></li><li><a href="module-eclairjs.Partitioner.html">Partitioner</a></li><li><a href="module-eclairjs.RangePartitioner.html">RangePartitioner</a></li><li><a href="module-eclairjs.RDD.html">RDD</a></li><li><a href="module-eclairjs.SparkConf.html">SparkConf</a></li><li><a href="module-eclairjs.SparkContext.html">SparkContext</a></li><li><a href="module-eclairjs.SparkFiles.html">SparkFiles</a></li><li><a href="module-eclairjs.SparkJobInfo.html">SparkJobInfo</a></li><li><a href="module-eclairjs.SparkStageInfo.html">SparkStageInfo</a></li><li><a href="module-eclairjs.SparkStatusTracker.html">SparkStatusTracker</a></li><li><a href="module-eclairjs.Tuple.html">Tuple</a></li><li><a href="module-eclairjs_ml_feature.Word2Vec.html">Word2Vec</a></li><li><a href="module-eclairjs_ml_feature.Word2VecModel.html">Word2VecModel</a></li><li><a href="module-eclairjs_mllib.MLUtils.html">MLUtils</a></li><li><a href="module-eclairjs_mllib_classification.ClassificationModel.html">ClassificationModel</a></li><li><a href="module-eclairjs_mllib_classification.LogisticRegressionModel.html">LogisticRegressionModel</a></li><li><a href="module-eclairjs_mllib_classification.LogisticRegressionWithLBFGS.html">LogisticRegressionWithLBFGS</a></li><li><a href="module-eclairjs_mllib_classification.LogisticRegressionWithSGD.html">LogisticRegressionWithSGD</a></li><li><a href="module-eclairjs_mllib_classification.NaiveBayes.html">NaiveBayes</a></li><li><a href="module-eclairjs_mllib_classification.NaiveBayesModel.html">NaiveBayesModel</a></li><li><a href="module-eclairjs_mllib_classification.SVMModel.html">SVMModel</a></li><li><a href="module-eclairjs_mllib_classification.SVMWithSGD.html">SVMWithSGD</a></li><li><a href="module-eclairjs_mllib_clustering.BisectingKMeans.html">BisectingKMeans</a></li><li><a href="module-eclairjs_mllib_clustering.BisectingKMeansModel.html">BisectingKMeansModel</a></li><li><a href="module-eclairjs_mllib_clustering.DistributedLDAModel.html">DistributedLDAModel</a></li><li><a href="module-eclairjs_mllib_clustering.KMeans.html">KMeans</a></li><li><a href="module-eclairjs_mllib_clustering.KMeansModel.html">KMeansModel</a></li><li><a href="module-eclairjs_mllib_clustering.LDA.html">LDA</a></li><li><a href="module-eclairjs_mllib_clustering.LDAModel.html">LDAModel</a></li><li><a href="module-eclairjs_mllib_clustering.LocalLDAModel.html">LocalLDAModel</a></li><li><a href="module-eclairjs_mllib_clustering.PowerIterationClustering.html">PowerIterationClustering</a></li><li><a href="module-eclairjs_mllib_clustering.PowerIterationClusteringAssignment.html">PowerIterationClusteringAssignment</a></li><li><a href="module-eclairjs_mllib_clustering.PowerIterationClusteringModel.html">PowerIterationClusteringModel</a></li><li><a href="module-eclairjs_mllib_evaluation.BinaryClassificationMetrics.html">BinaryClassificationMetrics</a></li><li><a href="module-eclairjs_mllib_evaluation.MulticlassMetrics.html">MulticlassMetrics</a></li><li><a href="module-eclairjs_mllib_evaluation.MultilabelMetrics.html">MultilabelMetrics</a></li><li><a href="module-eclairjs_mllib_evaluation.RankingMetrics.html">RankingMetrics</a></li><li><a href="module-eclairjs_mllib_evaluation.RegressionMetrics.html">RegressionMetrics</a></li><li><a href="module-eclairjs_mllib_feature.Word2Vec.html">Word2Vec</a></li><li><a href="module-eclairjs_mllib_feature.Word2VecModel.html">Word2VecModel</a></li><li><a href="module-eclairjs_mllib_fpm.AssociationRules.html">AssociationRules</a></li><li><a href="module-eclairjs_mllib_fpm.FPGrowth.html">FPGrowth</a></li><li><a href="module-eclairjs_mllib_fpm.FPGrowthModel.html">FPGrowthModel</a></li><li><a href="module-eclairjs_mllib_fpm.FreqItemset.html">FreqItemset</a></li><li><a href="module-eclairjs_mllib_fpm.PrefixSpan.html">PrefixSpan</a></li><li><a href="module-eclairjs_mllib_fpm.PrefixSpanFreqSequence.html">PrefixSpanFreqSequence</a></li><li><a href="module-eclairjs_mllib_fpm.PrefixSpanModel.html">PrefixSpanModel</a></li><li><a href="module-eclairjs_mllib_fpm.Rule.html">Rule</a></li><li><a href="module-eclairjs_mllib_linalg.DenseMatrix.html">DenseMatrix</a></li><li><a href="module-eclairjs_mllib_linalg.DenseVector.html">DenseVector</a></li><li><a href="module-eclairjs_mllib_linalg.Matrices.html">Matrices</a></li><li><a href="module-eclairjs_mllib_linalg.Matrix.html">Matrix</a></li><li><a href="module-eclairjs_mllib_linalg.QRDecomposition.html">QRDecomposition</a></li><li><a href="module-eclairjs_mllib_linalg.SingularValueDecomposition.html">SingularValueDecomposition</a></li><li><a href="module-eclairjs_mllib_linalg.SparseMatrix.html">SparseMatrix</a></li><li><a href="module-eclairjs_mllib_linalg.SparseVector.html">SparseVector</a></li><li><a href="module-eclairjs_mllib_linalg.Vector.html">Vector</a></li><li><a href="module-eclairjs_mllib_linalg.Vectors.html">Vectors</a></li><li><a href="module-eclairjs_mllib_linalg_distributed.DistributedMatrix.html">DistributedMatrix</a></li><li><a href="module-eclairjs_mllib_linalg_distributed.RowMatrix.html">RowMatrix</a></li><li><a href="module-eclairjs_mllib_optimization.Gradient.html">Gradient</a></li><li><a href="module-eclairjs_mllib_optimization.LBFGS.html">LBFGS</a></li><li><a href="module-eclairjs_mllib_optimization.LogisticGradient.html">LogisticGradient</a></li><li><a href="module-eclairjs_mllib_optimization.SquaredL2Updater.html">SquaredL2Updater</a></li><li><a href="module-eclairjs_mllib_optimization.Updater.html">Updater</a></li><li><a href="module-eclairjs_mllib_random.RandomRDDs.html">RandomRDDs</a></li><li><a href="module-eclairjs_mllib_recommendation.ALS.html">ALS</a></li><li><a href="module-eclairjs_mllib_recommendation.MatrixFactorizationModel.html">MatrixFactorizationModel</a></li><li><a href="module-eclairjs_mllib_recommendation.Rating.html">Rating</a></li><li><a href="module-eclairjs_mllib_regression.GeneralizedLinearModel.html">GeneralizedLinearModel</a></li><li><a href="module-eclairjs_mllib_regression.LabeledPoint.html">LabeledPoint</a></li><li><a href="module-eclairjs_mllib_regression.LinearRegressionModel.html">LinearRegressionModel</a></li><li><a href="module-eclairjs_mllib_regression.LinearRegressionWithSGD.html">LinearRegressionWithSGD</a></li><li><a href="module-eclairjs_mllib_tree.DecisionTree.html">DecisionTree</a></li><li><a href="module-eclairjs_mllib_tree.GradientBoostedTrees.html">GradientBoostedTrees</a></li><li><a href="module-eclairjs_mllib_tree.RandomForest.html">RandomForest</a></li><li><a href="module-eclairjs_mllib_tree_configuration.BoostingStrategy.html">BoostingStrategy</a></li><li><a href="module-eclairjs_mllib_tree_configuration.Strategy.html">Strategy</a></li><li><a href="module-eclairjs_mllib_tree_loss.Loss.html">Loss</a></li><li><a href="module-eclairjs_mllib_tree_model.DecisionTreeModel.html">DecisionTreeModel</a></li><li><a href="module-eclairjs_mllib_tree_model.GradientBoostedTreesModel.html">GradientBoostedTreesModel</a></li><li><a href="module-eclairjs_mllib_tree_model.RandomForestModel.html">RandomForestModel</a></li><li><a href="module-eclairjs_sql.Column.html">Column</a></li><li><a href="module-eclairjs_sql.DataFrame.html">DataFrame</a></li><li><a href="module-eclairjs_sql.DataFrameHolder.html">DataFrameHolder</a></li><li><a href="module-eclairjs_sql.DataFrameNaFunctions.html">DataFrameNaFunctions</a></li><li><a href="module-eclairjs_sql.DataFrameReader.html">DataFrameReader</a></li><li><a href="module-eclairjs_sql.DataFrameStatFunctions.html">DataFrameStatFunctions</a></li><li><a href="module-eclairjs_sql.DataFrameWriter.html">DataFrameWriter</a></li><li><a href="module-eclairjs_sql.functions.html">functions</a></li><li><a href="module-eclairjs_sql.GroupedData.html">GroupedData</a></li><li><a href="module-eclairjs_sql.Row.html">Row</a></li><li><a href="module-eclairjs_sql.RowFactory.html">RowFactory</a></li><li><a href="module-eclairjs_sql.SQLContext.html">SQLContext</a></li><li><a href="module-eclairjs_sql.SQLContext.QueryExecution.html">QueryExecution</a></li><li><a href="module-eclairjs_sql.SQLContext.SparkPlanner.html">SparkPlanner</a></li><li><a href="module-eclairjs_sql.SQLContext.SQLSession.html">SQLSession</a></li><li><a href="module-eclairjs_sql.SqlDate.html">SqlDate</a></li><li><a href="module-eclairjs_sql.SqlTimestamp.html">SqlTimestamp</a></li><li><a href="module-eclairjs_sql_execution.QueryExecution.html">QueryExecution</a></li><li><a href="module-eclairjs_sql_types.ArrayType.html">ArrayType</a></li><li><a href="module-eclairjs_sql_types.BinaryType.html">BinaryType</a></li><li><a href="module-eclairjs_sql_types.BooleanType.html">BooleanType</a></li><li><a href="module-eclairjs_sql_types.CalendarIntervalType.html">CalendarIntervalType</a></li><li><a href="module-eclairjs_sql_types.DataType.html">DataType</a></li><li><a href="module-eclairjs_sql_types.DataTypes.html">DataTypes</a></li><li><a href="module-eclairjs_sql_types.DateType.html">DateType</a></li><li><a href="module-eclairjs_sql_types.DoubleType.html">DoubleType</a></li><li><a href="module-eclairjs_sql_types.FloatType.html">FloatType</a></li><li><a href="module-eclairjs_sql_types.IntegerType.html">IntegerType</a></li><li><a href="module-eclairjs_sql_types.MapType.html">MapType</a></li><li><a href="module-eclairjs_sql_types.Metadata.html">Metadata</a></li><li><a href="module-eclairjs_sql_types.NullType.html">NullType</a></li><li><a href="module-eclairjs_sql_types.NumericType.html">NumericType</a></li><li><a href="module-eclairjs_sql_types.StringType.html">StringType</a></li><li><a href="module-eclairjs_sql_types.StructField.html">StructField</a></li><li><a href="module-eclairjs_sql_types.StructType.html">StructType</a></li><li><a href="module-eclairjs_sql_types.TimestampType.html">TimestampType</a></li><li><a href="module-eclairjs_storage.StorageLevel.html">StorageLevel</a></li><li><a href="module-eclairjs_streaming.Duration.html">Duration</a></li><li><a href="module-eclairjs_streaming.StreamingContext.html">StreamingContext</a></li><li><a href="module-eclairjs_streaming.Time.html">Time</a></li><li><a href="module-eclairjs_streaming_dstream.DStream.html">DStream</a></li><li><a href="module-eclairjs_streaming_dstream.PairDStream.html">PairDStream</a></li><li><a href="module-eclairjs_streaming_kafka.KafkaUtils.html">KafkaUtils</a></li><li><a href="module-eclairjs_streaming_twitter.TwitterAuthorization.html">TwitterAuthorization</a></li><li><a href="module-eclairjs_streaming_twitter.TwitterUtils.html">TwitterUtils</a></li><li><a href="PartialResult.html">PartialResult</a></li></ul><h3>Global</h3><ul><li><a href="global.html#module">module</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.3.2</a> on Mon Apr 18 2016 15:19:52 GMT-0400 (EDT)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
