<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: RDD.js</title>
    
    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">
    
    <h1 class="page-title">Source: RDD.js</h1>
    
    


    
    <section>
        <article>
            <pre class="prettyprint source"><code>/*
 * Copyright 2015 IBM Corp.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
  * @constructor
  * @classdesc A Resilient Distributed Dataset (RDD), the basic abstraction in Spark. Represents an immutable, 
 * partitioned collection of elements that can be operated on in parallel. 

 */
var RDD = function(jrdd) { // jrdd - JavaRDD object. don't expose this in the JSDocs for the public API
	var jvmObj = jrdd;
	this.logger = Logger.getLogger("RDD_js");
	JavaWrapper.call(this, jvmObj);
};

RDD.prototype = Object.create(JavaWrapper.prototype); 

RDD.prototype.constructor = RDD;

/**
 * Aggregate the elements of each partition, and then the results for all the partitions, using
 * given combine functions and a neutral "zero value". This function can return a different result
 * type, U, than the type of this RDD, T. Thus, we need one operation for merging a T into an U
 * and one operation for merging two U's, as in scala.TraversableOnce. Both of these functions are
 * allowed to modify and return their first argument instead of creating a new U to avoid memory
 * allocation.
 * @param {RDD} zeroValue - (undocumented)
 * @param {function} func1 seqOp - (undocumented) Function with two parameters
 * @param {function} func2 combOp - (undocumented) Function with two parameters
 * @returns {object}
 */
RDD.prototype.aggregate = function(zeroValue,func1,func2) {
   var zeroValue_uw = Utils.unwrapObject(zeroValue);
   var sv1 = Utils.createJavaParams(func1, 2);
   var fn1 = new org.eclairjs.nashorn.JSFunction2(sv1.funcStr, sv1.scopeVars);
   var sv2 = Utils.createJavaParams(func2, 2);
   var fn2 = new org.eclairjs.nashorn.JSFunction2(sv2.funcStr, sv2.scopeVars);
   return Utils.javaToJs(this.getJavaObject().aggregate(zeroValue_uw, fn1, fn2));
};

/**
 * Persist this RDD with the default storage level (`MEMORY_ONLY`).
 * @returns {RDD}
 */
RDD.prototype.cache = function() {
	return new RDD(this.getJavaObject().cache());
};

/**
 * Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of
 * elements (a, b) where a is in `this` and b is in `other`.
 * @param {RDD} other - (undocumented)
 * @returns {RDD}
 */
RDD.prototype.cartesian = function(other) {
   var other_uw = Utils.unwrapObject(other);
   return new RDD(this.getJavaObject().cartesian(other_uw));
};

/**
 * Mark this RDD for checkpointing. It will be saved to a file inside the checkpoint
 * directory set with `SparkContext#setCheckpointDir` and all references to its parent
 * RDDs will be removed. This function must be called before any job has been
 * executed on this RDD. It is strongly recommended that this RDD is persisted in
 * memory, otherwise saving it on a file will require recomputation.
 * @returns void
 */
RDD.prototype.checkpoint = function() {
   this.getJavaObject().checkpoint();
};

/**
 * Return a new RDD that is reduced into `numPartitions` partitions.
 *
 * This results in a narrow dependency, e.g. if you go from 1000 partitions
 * to 100 partitions, there will not be a shuffle, instead each of the 100
 * new partitions will claim 10 of the current partitions.
 *
 * However, if you're doing a drastic coalesce, e.g. to numPartitions = 1,
 * this may result in your computation taking place on fewer nodes than
 * you like (e.g. one node in the case of numPartitions = 1). To avoid this,
 * you can pass shuffle = true. This will add a shuffle step, but means the
 * current upstream partitions will be executed in parallel (per whatever
 * the current partitioning is).
 *
 * Note: With shuffle = true, you can actually coalesce to a larger number
 * of partitions. This is useful if you have a small number of partitions,
 * say 100, potentially with a few partitions being abnormally large. Calling
 * coalesce(1000, shuffle = true) will result in 1000 partitions with the
 * data distributed using a hash partitioner.
 * @param {int} numPartitions
 * @param {boolean} shuffle
 * @returns {RDD}
 */
RDD.prototype.coalesce = function(numPartitions,shuffle) {
    return new RDD(this.getJavaObject().coalesce(numPartitions, shuffle));
};

/**
 * Return an array that contains all of the elements in this RDD.
 * @returns {Array}
 */
RDD.prototype.collect = function() {
    var func = null; // See note below collectwithF - eventually want to pass func as param to this func
    var sv = func ? Utils.createJavaParams(func) : null;
    var fn = func ? new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars) : null;
	var res = func ? this.getJavaObject().collect(fn, "") : this.getJavaObject().collect();
	var results = [];
	for (var i = 0; i &lt; res.size(); i++) {
		var value = res.get(i);
		this.logger.debug("take value: " + value.getClass().getName());
		var o = Utils.javaToJs(value);
		this.logger.debug("take o:" + o.toString());
		results.push(o);
	}
	this.logger.debug("results " + results);
	return results;
};

/**
 * Return an RDD that contains all matching values by applying `f`.
 * Note: f is scala.PartialFunction which is not implemented yet - see above
 * @param {function} func - (undocumented) PartialFunction
 * @returns {RDD}
 * @private
 */
RDD.prototype.collectwithF = function(func) {
throw "not implemented by ElairJS";
//   var f_uw = Utils.unwrapObject(func);
//   var javaObject =  this.getJavaObject().collect(f_uw);
//   return new RDD(javaObject);
}

/**
 * Return the SparkContext that this RDD was created on.
 * @returns {SparkContext}
 */
RDD.prototype.context = function() {
    var javaObject =  this.getJavaObject().context();
    return new SparkContext(javaObject);
};

/**
 * Return the number of elements in the RDD.
 * @returns {integer}
 */
RDD.prototype.count = function() {
	var c = this.getJavaObject().count();
	return c;
};

/**
 * :: Experimental ::
 * Approximate version of count() that returns a potentially incomplete result
 * within a timeout, even if not all tasks have finished.
 * @param timeout {number} - (undocumented)
 * @param confidence {number} - (undocumented)
 * @returns {PartialResult}
 */
RDD.prototype.countApprox = function(timeout,confidence) {
    var javaObject =  this.getJavaObject().countApprox(timeout,confidence);
    return new PartialResult(javaObject);
};

/**
 * Return approximate number of distinct elements in the RDD.
 *
 * The algorithm used is based on streamlib's implementation of "HyperLogLog in Practice:
 * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm", available
 * &lt;a href="http://dx.doi.org/10.1145/2452376.2452456">here&lt;/a>.
 *
 * @param {number} relativeSD  Relative accuracy. Smaller values create counters that require more space.
 *                   It must be greater than 0.000017.
 * @returns {number}
 */
RDD.prototype.countApproxDistinct = function(relativeSD) {
    return  this.getJavaObject().countApproxDistinct(relativeSD);
};

/**
 * :: Experimental ::
 * Return approximate number of distinct elements in the RDD.
 *
 * The algorithm used is based on streamlib's implementation of "HyperLogLog in Practice:
 * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm", available
 * &lt;a href="http://dx.doi.org/10.1145/2452376.2452456">here&lt;/a>.
 *
 * The relative accuracy is approximately `1.054 / sqrt(2^p)`. Setting a nonzero `sp &gt; p`
 * would trigger sparse representation of registers, which may reduce the memory consumption
 * and increase accuracy when the cardinality is small.
 *
 * @param {number} p  The precision value for the normal set.
 *          `p` must be a value between 4 and `sp` if `sp` is not zero (32 max).
 * @param {number} sp  The precision value for the sparse set, between 0 and 32.
 *           If `sp` equals 0, the sparse representation is skipped.
 * @returns {number}
 */
RDD.prototype.countApproxDistinctwithSp = function(p,sp) {
    return  this.getJavaObject().countApproxDistinct(p,sp);
};

/**
 * Return the count of each unique value in this RDD as a local map of (value, count) pairs.
 *
 * Note that this method should only be used if the resulting map is expected to be small, as
 * the whole thing is loaded into the driver's memory.
 * To handle very large results, consider using rdd.map(x =&gt; (x, 1L)).reduceByKey(_ + _), which
 * returns an RDD[T, Long] instead of a map.
 * @returns {Map} - need to figureout return structure probably just JSON construct
 * @private
 */
RDD.prototype.countByValue = function() {
throw "not implemented by ElairJS";
//   var javaObject =  this.getJavaObject().countByValue();
//   return new Map(javaObject);
};

/**
 * :: Experimental ::
 * Approximate version of countByValue().
 * @param timeout {number} - (undocumented)
 * @param confidence {number} - (undocumented)
 * @returns {PartialResult}
 */
RDD.prototype.countByValueApprox = function(timeout,confidence) {
    var javaObject =  this.getJavaObject().countByValueApprox(timeout,confidence);
    return new PartialResult(javaObject);
};

/**
 * Get the list of dependencies of this RDD, taking into account whether the
 * RDD is checkpointed or not.
 * @returns {Seq} - need to figure out return structure probably just array
 * @private
 */
RDD.prototype.dependencies = function() {
throw "not implemented by ElairJS";
//   var javaObject =  this.getJavaObject().dependencies();
//   return new Seq(javaObject);
};

/**
 * Return a new RDD containing the distinct elements in this RDD.
 * @param {int} numPartitions (optional)
 * @returns {RDD}
 */
RDD.prototype.distinct = function(numPartitions) {
    var javaObject =  numPartitions ? this.getJavaObject(numPartitions).distinct() :
        this.getJavaObject().distinct();
    return new RDD(javaObject);
};

/**
 * Return a new RDD containing only the elements that satisfy a predicate.
 * @param {function} func - (undocumented) Function with one parameter
 * @returns {RDD}
 */
RDD.prototype.filter = function(func) {
	var sv = Utils.createJavaParams(func);
	var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    var javaObject =  this.getJavaObject().filter(fn);
    return new RDD(javaObject);
};

/**
 * Filters this RDD with p, where p takes an additional parameter of type A.  This
 * additional parameter is produced by constructA, which is called in each
 * partition with the index of that partition.
 * Note: Doesn't make sense for JavaScript.
 * @param constructA
 * @returns {RDD}
 * @private
 */
RDD.prototype.filterWith = function(constructA) {
throw "not implemented by ElairJS";
    //var sv = Utils.createJavaParams(constructA);
    //var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    //var javaObject =  this.getJavaObject().filterWith(fn);
    //return new RDD(javaObject);
};

/**
 * Return the first element in this RDD.
 * @returns {object}
 */
RDD.prototype.first = function() {
    var result = this.getJavaObject().first();
    var o = Utils.javaToJs(result);
    return (o);   
};

/**
* Return a new RDD by first applying a function to all elements of this RDD, and then flattening the results.
* @param {function} func - (undocumented) - Function with one parameter
* @returns {RDD}
*/
RDD.prototype.flatMap = function(func) {
	var sv = Utils.createJavaParams(func);
	var fn = new org.eclairjs.nashorn.JSFlatMapFunction(sv.funcStr, sv.scopeVars);
    var javaObject =  this.getJavaObject().flatMap(fn);
    return new RDD(javaObject);
};

/**
 * FlatMaps f over this RDD, where f takes an additional parameter of type A.  This
 * additional parameter is produced by constructA, which is called in each
 * partition with the index of that partition.
 * Note: Doesn't make sense for JavaScript.
 * @returns {RDD}
 * @private
 */
RDD.prototype.flatMapWith = function(constructA,preservesPartitioning) {
throw "not implemented by ElairJS";
    //var sv = Utils.createJavaParams(constructA);
    //var preserves = preservesPartitioning || false;
    //var javaObject =  this.getJavaObject().flatMapWith(fn,preservesPartitioning);
    //return new RDD(javaObject);
};

/**
 * Aggregate the elements of each partition, and then the results for all the partitions, using a
 * given associative and commutative function and a neutral "zero value". The function
 * op(t1, t2) is allowed to modify t1 and return it as its result value to avoid object
 * allocation; however, it should not modify t2.
 *
 * This behaves somewhat differently from fold operations implemented for non-distributed
 * collections in functional languages like Scala. This fold operation may be applied to
 * partitions individually, and then fold those results into the final result, rather than
 * apply the fold to each element sequentially in some defined ordering. For functions
 * that are not commutative, the result may differ from that of a fold applied to a
 * non-distributed collection.
 * @param {RDD} zeroValue - (undocumented)
 * @param {function} func - (undocumented) Function with two parameters
 * @returns {object}
 */
RDD.prototype.fold = function(zeroValue, func) {
    var zeroValue_uw = Utils.unwrapObject(zeroValue);
    var sv = Utils.createJavaParams(func, 2);
    var fn = new org.eclairjs.nashorn.JSFunction2(sv.funcStr, sv.scopeVars);
    var result = this.getJavaObject().fold(zeroValue_uw, fn);
    var o = Utils.javaToJs(result);
    return (o); 
};

/**
 * Applies a function to all elements of this RDD.
 * @example
 * rdd3.foreach(function(record) {
 *    var connection = createNewConnection()
 *    connection.send(record);	
 *    connection.close()
 * });
 * @param {function} func - Function with one parameter that returns void
 * @returns {void}
 */
RDD.prototype.foreach = function(func) {
	var sv = Utils.createJavaParams(func);
	var fn = new org.eclairjs.nashorn.JSVoidFunction(sv.funcStr, sv.scopeVars);
	this.getJavaObject().foreach(fn);
};

/**
 * Applies a function to each partition of this RDD.
 * @example
 * rdd3.foreachPartition(function(partitionOfRecords) {
 *    var connection = createNewConnection()
 *    partitionOfRecords.forEach(function(record){
 *       connection.send(record);	
 *    });
 *    connection.close()
 * });
 * @param {function} func - Function with one Array parameter that returns void
 * @returns {void}
 */
RDD.prototype.foreachPartition = function(func) {
	var sv = Utils.createJavaParams(func);
	var fn = new org.eclairjs.nashorn.JSVoidFunction(sv.funcStr, sv.scopeVars);
	this.getJavaObject().foreachPartition(fn);
};

/**
 * Applies f to each element of this RDD, where f takes an additional parameter of type A.
 * This additional parameter is produced by constructA, which is called in each
 * partition with the index of that partition.
 * Note: Doesn't make sense for JavaScript.
 * @param {constructA} - (undocumented)
 * @returns {void}
 * @private
 */
RDD.prototype.foreachWith = function(constructA) {
throw "not implemented by ElairJS";
    //var sv = Utils.createJavaParams(constructA);
    //var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    //this.getJavaObject().foreachWith(fn);
};

/**
 * Gets the name of the directory to which this RDD was checkpointed.
 * This is not defined if the RDD is checkpointed locally.
 * @returns {string}
 */
RDD.prototype.getCheckpointFile = function() {
   return  this.getJavaObject().getCheckpointFile();
};

/**
 * @returns {StorageLevel}
 */
RDD.prototype.getStorageLevel = function() {
    var javaObject =  this.getJavaObject().getStorageLevel();
    return new StorageLevel(javaObject);
};

/**
 * Return an RDD created by coalescing all elements within each partition into an array.
 * @returns {RDD}
 */
RDD.prototype.glom = function() {
    var javaObject =  this.getJavaObject().glom();
    return new RDD(javaObject);
};

/**
 * Return an RDD of grouped items. Each group consists of a key and a sequence of elements
 * mapping to that key. The ordering of elements within each group is not guaranteed, and
 * may even differ each time the resulting RDD is evaluated.
 *
 * Note: This operation may be very expensive. If you are grouping in order to perform an
 * aggregation (such as a sum or average) over each key, using {@link aggregateByKey}
 * or {@link reduceByKey} will provide much better performance.
 * @param {function} func - (undocumented) Function with one parameter
 * @param {number} numPartitions - (optional) How many partitions to use in the resulting RDD (if non-zero partitioner is ignored)
 * @param {Partitioner} partitioner - (optional) Partitioner to use for the resulting RDD
 * @returns {RDD}
 */
RDD.prototype.groupBy = function(func,numPartitions,partitioner) {
    var sv = Utils.createJavaParams(func);
    var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    var partitioner_uw = Utils.unwrapObject(partitioner);
    var result = numPartitions ? this.getJavaObject().groupBy(fn,numPartitions) : 
        partitioner_uw ? this.getJavaObject().groupBy(fn,partitioner_uw) : this.getJavaObject().groupBy(fn);
    return new RDD(result);
};

/**
 * A unique ID for this RDD (within its SparkContext).
 * @returns {int}
 */
RDD.prototype.id = function() {
   return this.getJavaObject().id();
};

/**
 * Return the intersection of this RDD and another one. The output will not contain any duplicate
 * elements, even if the input RDDs did.
 *
 * Note that this method performs a shuffle internally.
 * @param {RDD} other - the other RDD
 * @param {number} numPartitions  How many partitions to use in the resulting RDD (if non-zero partitioner is ignored)
 * @param {Partitioner} partitioner  Partitioner to use for the resulting RDD
 * @returns {RDD}
 */
RDD.prototype.intersection = function(other,numPartitions,partitioner) {
    var other_uw = Utils.unwrapObject(other);
    var partitioner_uw = Utils.unwrapObject(partitioner);
    var result = numPartitions ? this.getJavaObject().intersection(other_uw,numPartitions) :
        partitioner_uw ? this.getJavaObject().intersection(other_uw,partitioner_uw) : 
        this.getJavaObject().intersection(other_uw);
    return new RDD(result);
};

/**
 * Return whether this RDD is checkpointed and materialized, either reliably or locally.
 * @returns {boolean}
 */
RDD.prototype.isCheckpointed = function() {
    return this.getJavaObject().isCheckpointed();
};

/**
 * @note due to complications in the internal implementation, this method will raise an
 * exception if called on an RDD of `Nothing` or `Null`. This may be come up in practice
 * because, for example, the type of `parallelize(Seq())` is `RDD[Nothing]`.
 * (`parallelize(Seq())` should be avoided anyway in favor of `parallelize(Seq[T]())`.)
 *         may be empty even when it has at least 1 partition.
 * @returns {boolean}  true if and only if the RDD contains no elements at all. Note that an RDD
 */
RDD.prototype.isEmpty = function() {
    return  this.getJavaObject().isEmpty();
};

/**
 * Creates tuples of the elements in this RDD by applying `f`.
 * @param {function} func - (undocumented)
 * @returns {RDD}
 */
RDD.prototype.keyBy = function(func) {
    var sv = Utils.createJavaParams(func);
    var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    var javaObject =  this.getJavaObject().keyBy(fn);
    return new RDD(javaObject);
};

/**
 * Mark this RDD for local checkpointing using Spark's existing caching layer.
 *
 * This method is for users who wish to truncate RDD lineages while skipping the expensive
 * step of replicating the materialized data in a reliable distributed file system. This is
 * useful for RDDs with long lineages that need to be truncated periodically (e.g. GraphX).
 *
 * Local checkpointing sacrifices fault-tolerance for performance. In particular, checkpointed
 * data is written to ephemeral local storage in the executors instead of to a reliable,
 * fault-tolerant storage. The effect is that if an executor fails during the computation,
 * the checkpointed data may no longer be accessible, causing an irrecoverable job failure.
 *
 * This is NOT safe to use with dynamic allocation, which removes executors along
 * with their cached blocks. If you must use both features, you are advised to set
 * `spark.dynamicAllocation.cachedExecutorIdleTimeout` to a high value.
 *
 * The checkpoint directory set through `SparkContext#setCheckpointDir` is not used.
 * @returns {RDD}
 */
RDD.prototype.localCheckpoint = function() {
    var javaObject =  this.getJavaObject().localCheckpoint();
    return new RDD(javaObject);
};

/**
 * Return a new RDD by applying a function to all elements of this RDD.
 * @param {function} func - (undocumented) Function with one parameter
 * @returns {RDD}
 */
RDD.prototype.map = function(func) {
	var sv = Utils.createJavaParams(func);
	var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    var javaObject =  this.getJavaObject().map(fn);
    return new RDD(javaObject);
};

/**
 * Return a new RDD by applying a function to each partition of this RDD. 
 * Similar to map, but runs separately on each partition (block) of the RDD, so func must accept an Array.  
 * func should return a array rather than a single item.
 * @param {function} func - (undocumented) Function with one parameter
 * @param {boolean} preservesPartitioning - (optional)
 * @returns {RDD}
 */
RDD.prototype.mapPartitions = function(func,preservesPartitioning) {
	var sv = Utils.createJavaParams(func);
	var fn = new org.eclairjs.nashorn.JSFlatMapFunction(sv.funcStr, sv.scopeVars);
    var javaObject =  this.getJavaObject().mapPartitions(fn,preservesPartitioning);
    return new RDD(javaObject);
};

/**
 * Return a new RDD by applying a function to each partition of this RDD, while tracking the index
 * of the original partition.
 *
 * `preservesPartitioning` indicates whether the input function preserves the partitioner, which
 * should be `false` unless this is a pair RDD and the input function doesn't modify the keys.
 * @param {function} func - (undocumented) Function with one parameter
 * @param {boolean} preservesPartitioning - (optional)
 * @returns {RDD}
 */
RDD.prototype.mapPartitionsWithIndex = function(func,preservesPartitioning) {
    var sv = Utils.createJavaParams(func);
    var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    var javaObject =  this.getJavaObject().mapPartitionsWithIndex(fn,preservesPartitioning);
    return new RDD(javaObject);
};

/**
 * Return a new RDD by applying a function to each partition of this RDD, while tracking the index
 * of the original partition.
 * @param {function} func - (undocumented) Function with one parameter
 * @param {boolean} preservesPartitioning - (optional)
 * @returns {RDD}
 */
RDD.prototype.mapPartitionsWithSplit = function(func,preservesPartitioning) {
    var sv = Utils.createJavaParams(func);
    var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    var javaObject =  this.getJavaObject().mapPartitionsWithSplit(fn,preservesPartitioning);
    return new RDD(javaObject);
};

/**
 * Maps f over this RDD, where f takes an additional parameter of type A.  This
 * additional parameter is produced by constructA, which is called in each
 * partition with the index of that partition.
 * Note: Doesn't make sense for JavaScript.
 * @param {function}
 * @param {boolean}
 * @returns {RDD}
 * @private
 */
RDD.prototype.mapWith = function(constructA,preservesPartitioning) {
throw "not implemented by ElairJS";
    //var sv = Utils.createJavaParams(constructA);
    //var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    //var javaObject =  this.getJavaObject().mapWith(fn,preservesPartitioning);
    //return new RDD(javaObject);
};

/**
 * Return a new RDD by applying a function to all elements of this RDD.
 * @param (function) func - (undocumented) Function with one parameter that returns tuple
 * @returns {RDD}
 */
RDD.prototype.mapToPair = function(func) {
	var sv = Utils.createJavaParams(func);
	var fn = new org.eclairjs.nashorn.JSPairFunction(sv.funcStr, sv.scopeVars);
	var result = new RDD(this.getJavaObject().mapToPair(fn));
	return result;
};

/**
 * Returns the max of this RDD as defined by the implicit Ordering[T].
 * @param (function) comparator - Compares its two arguments for order. Returns a negative integer, zero, or a positive integer as the first argument is less than, equal to, or greater than the second.
 * @returns {object}  the maximum element of the RDD
 */
RDD.prototype.max = function(comparator) {
    var sv = Utils.createJavaParams(comparator, 2);
    var fn = new org.eclairjs.nashorn.JSComparator(sv.funcStr, sv.scopeVars);
    return  this.getJavaObject().max(fn);
};

/**
 * Returns the min of this RDD as defined by the implicit Ordering[T].
 * @param (function) comparator - Compares its two arguments for order. Returns a negative integer, zero, or a positive integer as the second argument is less than, equal to, or greater than the first.
 * @returns {object}  the minimum element of the RDD
 */
RDD.prototype.min = function(comparator) {
    var sv = Utils.createJavaParams(comparator, 2);
    var fn = new org.eclairjs.nashorn.JSComparator(sv.funcStr, sv.scopeVars);
    return  this.getJavaObject().min(fn);
};

/**
 * A friendly name for this RDD
 * @returns {string}
 */
RDD.prototype.name = function() {
    return  this.getJavaObject().name();
};

/**
 * This does not make sense for JavaScript as everything in JS is handled as a double. 
 * @returns {RDD}
 * @private
 */
RDD.prototype.numericRDDToDoubleRDDFunctions = function(rdd) {
throw "not implemented by ElairJS";
    //var rdd_uw = Utils.unwrapObject(rdd);
    //var javaObject = this.getJavaObject().numericRDDToDoubleRDDFunctions(rdd_uw);
    //return new RDD(javaObject);
};

/**
 * @param {StorageLevel} newLevel
 * @returns {RDD}
 */
RDD.prototype.persist = function(newLevel) {
    var newLevel_uw = newLevel ? Utils.unwrapObject(newLevel) : null;
    var javaObject = newLevel_uw ? this.getJavaObject().persist(newLevel_uw) : this.getJavaObject().persist();
    return new RDD(javaObject);
};

/**
 * Return an RDD created by piping elements to a forked external process.
 * The print behavior can be customized by providing two functions.
 *
 * @param {Seq|string} command - command to run in forked process.
 * @param {Map} env -  environment variables to set.
 * @param {func} printPipeContext - (optional) Before piping elements, this function is called as an opportunity
 *                         to pipe context data. Print line function (like out.println) will be
 *                         passed as printPipeContext's parameter.
 * @param {func} printRDDElement - (optional) Use this function to customize how to pipe elements.
 *                        This function will be called with each RDD element as the 1st parameter,
 *                        and the print line function (like out.println()) as the 2nd parameter.
 *                        An example of pipe the RDD data of groupBy() in a streaming way,
 *                        instead of constructing a huge String to concat all the elements:
 *                        def printRDDElement(record:(String, Seq[String]), f:String=&gt;Unit) =
 *                          for (e &lt;- record._2){f(e)}
 * @param {boolean} separateWorkingDir - (optional) Use separate working directories for each task.
 * @returns {RDD}  the result RDD
 */
RDD.prototype.pipe = function(command,env,printPipeContext,printRDDElement,separateWorkingDir) {
    var command_uw = typeof command === 'object' ? Utils.unwrapObject(command) : command;
    var env_uw = env ? Utils.unwrapObject(env) : null;
    var sv = printPipeContext ? Utils.createJavaParams(printPipeContext) : null;
    var fn = sv ? new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars) : null;
    var sv2 = printRDDElement ? Utils.createJavaParams(printRDDElement) : null;
    var fn2 = sv2 ? new org.eclairjs.nashorn.JSFunction(sv2.funcStr, sv2.scopeVars) : null;
    var result = fn && fn2 ? this.getJavaObject().pipe(command_uw,env_uw,fn,fn2,separateWorkingDir) :
        env_ua ? this.getJavaObject().pipe(command_uw,env_uw) : this.getJavaObject().pipe(command_uw);

    return new RDD(result);
};

/**
 * Get the preferred locations of a partition, taking into account whether the
 * RDD is checkpointed.
 * @returns {Seq}
 * @private
 */
RDD.prototype.preferredLocations = function(split) {
throw "not implemented by ElairJS";
//   var split_uw = Utils.unwrapObject(split);
//   var javaObject =  this.getJavaObject().preferredLocations(split_uw);
//   return new Seq(javaObject);
};

/**
 * Randomly splits this RDD with the provided weights.
 *
 * @param {number[]} weights - weights for splits, will be normalized if they don't sum to 1
 * @param {number} seed - random seed
 * @returns {RDD[]}  split RDDs in an array
 * @private
 */
RDD.prototype.randomSplit = function(weights,seed) {
    var res = this.getJavaObject().randomSplit(weights,seed);
    var results = [];
    for (var i = 0; i &lt; res.size(); i++) {
        var value = res.get(i);
        results.push(new RDD(value));
    }
    return results;
};

/**
 * @private
 */
RDD.prototype.rddToAsyncRDDActions = function(rdd) {
throw "not implemented by ElairJS";
//   var rdd_uw = Utils.unwrapObject(rdd);
//   return  this.getJavaObject().rddToAsyncRDDActions(rdd_uw);
};

/**
 * @private
 */
RDD.prototype.rddToOrderedRDDFunctions = function(rdd) {
throw "not implemented by ElairJS";
//   var rdd_uw = Utils.unwrapObject(rdd);
//   return  this.getJavaObject().rddToOrderedRDDFunctions(rdd_uw);
};

/**
 * @private
 */
RDD.prototype.rddToPairRDDFunctions = function(rdd) {
throw "not implemented by ElairJS";
//   var rdd_uw = Utils.unwrapObject(rdd);
//   return  this.getJavaObject().rddToPairRDDFunctions(rdd_uw);
};

/**
 * @private
 */
RDD.prototype.rddToSequenceFileRDDFunctions = function(rdd) {
throw "not implemented by ElairJS";
//   var rdd_uw = Utils.unwrapObject(rdd);
//   return  this.getJavaObject().rddToSequenceFileRDDFunctions(rdd_uw);
};

/**
 * Reduces the elements of this RDD using the specified commutative and
 * associative binary operator.
 * {function} func - (undocumented) Function with two parameters
 * @returns {RDD}
 */
RDD.prototype.reduce = function(func) {
    var sv = Utils.createJavaParams(func, 2);
    var fn = new org.eclairjs.nashorn.JSFunction2(sv.funcStr, sv.scopeVars);
    var javaObject =  this.getJavaObject().reduce(fn);
    return Utils.javaToJs(javaObject);
};

/**
 * Reduces the elements of this RDD using the specified function.
 * @param {function} func - Function with two parameters
 * @returns {RDD}
 * @deprecated Use reduce instead
 */
RDD.prototype.reduceByKey = function(func) {
	var sv = Utils.createJavaParams(func, 2);
	var fn = new org.eclairjs.nashorn.JSFunction2(sv.funcStr, sv.scopeVars);
	var result = this.getJavaObject().reduceByKey(fn);
	return new RDD(result);
};

/**
 * Return a new RDD that has exactly numPartitions partitions.
 *
 * Can increase or decrease the level of parallelism in this RDD. Internally, this uses
 * a shuffle to redistribute data.
 *
 * If you are decreasing the number of partitions in this RDD, consider using `coalesce`,
 * which can avoid performing a shuffle.
 * @param {int} numPartitions - (undocumented)
 * @returns {RDD}
 */
RDD.prototype.repartition = function(numPartitions) {
    var javaObject =  this.getJavaObject().repartition(numPartitions);
    return new RDD(javaObject);
};

/**
 * Return a sampled subset of this RDD.
 *
 * @param {boolean} withReplacement  can elements be sampled multiple times (replaced when sampled out)
 * @param {number} fraction  expected size of the sample as a fraction of this RDD's size
 *  without replacement: probability that each element is chosen; fraction must be [0, 1]
 *  with replacement: expected number of times each element is chosen; fraction must be >= 0
 * @param {number} seed  seed for the random number generator
 * @returns {RDD}
 */
RDD.prototype.sample = function(withReplacement,fraction,seed) {
    var javaObject =  this.getJavaObject().sample(withReplacement,fraction,seed);
    return new RDD(javaObject);
};

/**
 * Save this RDD as a SequenceFile of serialized objects.
 * @param {string} path
 * @returns {void}
 */
RDD.prototype.saveAsObjectFile = function(path) {
    this.getJavaObject().saveAsObjectFile(path);
};

/**
 * Save this RDD as a text file, using string representations of elements.
 * @param {string} path
 * @returns {void}
 */
RDD.prototype.saveAsTextFile = function(path) {
    this.getJavaObject().saveAsTextFile(path);
};

/**
 * Save this RDD as a compressed text file, using string representations of elements.
 * @param path {string}
 * @param codec {org.apache.hadoop.io.compress.CompressionCodec}
 * @returns {void} 
 * @private
 */
RDD.prototype.saveAsTextFilewithCodec = function(path,codec) {
throw "not implemented by ElairJS";
    //var codec_uw = Utils.unwrapObject(codec);
    //this.getJavaObject().saveAsTextFile(path,codec_uw);
};

/**
 * Assign a name to this RDD.
 * @returns {RDD}
 */
RDD.prototype.setName = function(_name) {
    var javaObject = this.getJavaObject().setName(_name);
    return new RDD(javaObject);
};

/**
 * Return this RDD sorted by the given key function.
 * @param {function} func - (undocumented) Function with one parameter
 * @param {boolean} ascending
 * @param {int} numPartitions
 * @returns {RDD}
 */
RDD.prototype.sortBy = function(func,ascending,numPartitions) {
    var sv = Utils.createJavaParams(func);
    var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    var javaObject =  this.getJavaObject().sortBy(fn,ascending,numPartitions);
    return new RDD(javaObject);
};

/**
 * Return this RDD sorted by the given key function.
 * @param {boolean} ascending
 * @returns {RDD}
 * @deprecated Use sortBy instead
 */
RDD.prototype.sortByKey = function(ascending) {
	var result = new RDD(this.getJavaObject().sortByKey(ascending));
	return result;
};

/**
 * The SparkContext that created this RDD.
 * @returns {SparkContext}
 */
RDD.prototype.sparkContext = function() {
    var javaObject = this.getJavaObject().sparkContext();
    return new SparkContext(javaObject);
};

/**
 * Return an RDD with the elements from `this` that are not in `other`.
 * @param other {RDD}
 * @param numPartitions {int} (optional)
 * @param p {Partition} (optional - ignored if numPartitions is non-zero)
 * @returns {RDD}
 */
RDD.prototype.subtract = function(other,numPartitions,p) {
    var other_uw = Utils.unwrapObject(other);
    var p_uw = p ? Utils.unwrapObject(p) : null;
    var result = numPartitions ? this.getJavaObject().subtract(other_uw,numPartitions) :
        p_uw ? this.getJavaObject().subtract(other_uw,p_uw) : this.getJavaObject().subtract(other_uw);
    return new RDD(result);
};

/**
 * Take the first num elements of the RDD.
 * @param {int} num
 * @returns {Array}
 */
RDD.prototype.take = function(num) {
	var res = this.getJavaObject().take(num);
	this.logger.debug("take " + res.getClass().getName());
	var results = [];
	for (var i = 0; i &lt; res.size(); i++) {
		var value = res.get(i);
		this.logger.debug("take value: " + value.getClass().getName());
		var o = Utils.javaToJs(value);
		this.logger.debug("take o:" + o.toString());
		results.push(o);
	}
	this.logger.debug("results " + results);
	return results;
};

/**
 * Returns the first k (smallest) elements from this RDD as defined by the specified
 * implicit Ordering[T] and maintains the ordering. This does the opposite of {@link top}.
 * For example:
 * {{{
 *   sc.parallelize(Seq(10, 4, 2, 12, 3)).takeOrdered(1)
 *   // returns Array(2)
 *
 *   sc.parallelize(Seq(2, 3, 4, 5, 6)).takeOrdered(2)
 *   // returns Array(2, 3)
 * }}}
 *
 * @param {number} num - the number of elements to return
 * @returns {Array}  an array of top elements
 */
RDD.prototype.takeOrdered = function(num) {
    var res = this.getJavaObject().takeOrdered(num);
    var results = [];
    for (var i = 0; i &lt; res.size(); i++) {
        var value = res.get(i);
        var o = Utils.javaToJs(value);
        results.push(o);
    }
    return results;
};

/**
 * Return a fixed-size sampled subset of this RDD in an array
 *
 * @param {boolean} withReplacement  whether sampling is done with replacement
 * @param {number} num  size of the returned sample
 * @param {number} seed  seed for the random number generator
 * @returns {Array}  sample of specified size in an array
 */
RDD.prototype.takeSample = function(withReplacement,num,seed) {
    var res = this.getJavaObject().takeSample(withReplacement,num,seed);
    var results = [];
    for (var i = 0; i &lt; res.size(); i++) {
        var value = res.get(i);
        var o = Utils.javaToJs(value);
        results.push(o);
    }
    return results;
};

/**
 * Return an array that contains all of the elements in this RDD.
 * @returns {Array}
 */
RDD.prototype.toArray = function() {
	var res = this.getJavaObject().toArray();
	var results = [];
	for (var i = 0; i &lt; res.length; i++) {
		var value = res[i];
		var o = Utils.javaToJs(value);
		results.push(o);
	}
	return results;	
};

/**
 * A description of this RDD and its recursive dependencies for debugging.
 * @returns {string}
 */
RDD.prototype.toDebugString = function() {
    return  this.getJavaObject().toDebugString();
};

/**
 * Returns the top k (largest) elements from this RDD as defined by the specified
 * implicit Ordering[T]. This does the opposite of {@link takeOrdered}. For example:
 * {{{
 *   sc.parallelize(Seq(10, 4, 2, 12, 3)).top(1)
 *   // returns Array(12)
 *
 *   sc.parallelize(Seq(2, 3, 4, 5, 6)).top(2)
 *   // returns Array(6, 5)
 * }}}
 *
 * @param {number} num  k, the number of top elements to return
 * @returns {Array}  an array of top elements
 */
RDD.prototype.top = function(num) {
    var res = this.getJavaObject().top(num);
    var results = [];
    for (var i = 0; i &lt; res.length; i++) {
        var value = res[i];
        var o = Utils.javaToJs(value);
        results.push(o);
    }
    return results;
};

/**
 * @returns {string}
 */
RDD.prototype.toString = function() {
   return this.getJavaObject().toString();
};

/**
 * Aggregates the elements of this RDD in a multi-level tree pattern.
 *
 * @param zeroValue - (undocumented)
 * @param {function} func1 - (undocumented) Function with two parameters
 * @param {function} func2 combOp - (undocumented) Function with two parameters
 * @see [[org.apache.spark.rdd.RDD#aggregate]]
 * @returns {object}
 */
RDD.prototype.treeAggregate = function(zeroValue,func1,func2) {
    var sv1 = Utils.createJavaParams(func1, 2);
    var fn1 = new org.eclairjs.nashorn.JSFunction2(sv1.funcStr, sv1.scopeVars);
    var sv2 = Utils.createJavaParams(func2, 2);
    var fn2 = new org.eclairjs.nashorn.JSFunction2(sv2.funcStr, sv2.scopeVars);
    return Utils.javaToJs(this.getJavaObject().treeAggregate(zeroValue_uw, fn1, fn2));
};

/**
 * Reduces the elements of this RDD in a multi-level tree pattern.
 *
 * @param {function} func - (undocumented) Function with one parameter
 * @param {number} depth  suggested depth of the tree (default: 2)
 * @see [[org.apache.spark.rdd.RDD#reduce]]
 * @returns {object}
 */
RDD.prototype.treeReduce = function(func,depth) {
    var sv = Utils.createJavaParams(func);
    var fn = new org.eclairjs.nashorn.JSFunction(sv.funcStr, sv.scopeVars);
    var javaObject = this.getJavaObject().treeReduce(fn,depth);
    return Utils.javaToJs(javaObject);
};

/**
 * Return the union of this RDD and another one. Any identical elements will appear multiple
 * times (use `.distinct()` to eliminate them).
 * @param {RDD} other - (undocumented)
 * @returns {RDD}
 */
RDD.prototype.union = function(other) {
    var other_uw = Utils.unwrapObject(other);
    var javaObject =  this.getJavaObject().union(other_uw);
    return new RDD(javaObject);
};

/**
 * Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
 *
 * @param {boolean} blocking -  Whether to block until all blocks are deleted.
 * @returns {RDD}  This RDD.
 */
RDD.prototype.unpersist = function(blocking) {
    var javaObject =  this.getJavaObject().unpersist(blocking);
    return new RDD(javaObject);
};

/**
 * Zips this RDD with another one, returning key-value pairs with the first element in each RDD,
 * second element in each RDD, etc. Assumes that the two RDDs have the *same number of
 * partitions* and the *same number of elements in each partition* (e.g. one was made through
 * a map on the other).
 * @param {RDD} other - (undocumented)
 * @returns {RDD}
 */
RDD.prototype.zip = function(other) {
    var other_uw = Utils.unwrapObject(other);
    var javaObject = this.getJavaObject().zip(other_uw);
    return new RDD(javaObject);
};

/**
 * Zip this RDD's partitions with another RDD and return a new RDD by
 * applying a function to the zipped partitions. Assumes that both the RDDs have the
 * same number of partitions, but does not require them to have the same number
 * of elements in each partition.
 *
 * @param {RDD} rdd2
 * @param {function} func - Function with two parameters
 * @param {boolean} preservesPartitioning - (optional)
 * @returns {RDD}
 */
RDD.prototype.zipPartitions = function(rdd2,func,preservesPartitioning) {
    var rdd2_uw = Utils.unwrapObject(rdd2);
    var sv = Utils.createJavaParams(func, 2);
    var fn = new org.eclairjs.nashorn.JSFlatMapFunction2(sv.funcStr, sv.scopeVars);
    var result = this.getJavaObject().zipPartitions(rdd2_uw,fn);
    return new RDD(result);
};

/**
 * Zip this RDD's partitions with one (or more) RDD(s) and return a new RDD by
 * applying a function to the zipped partitions. Assumes that all the RDDs have the
 * same number of partitions, but does not require them to have the same number
 * of elements in each partition.
 *
 * Note: To support params rdd3, rdd4 we need to implement JSFunction3 and JSFunction4
 * Renaming this version and making this private for now.
 *
 * @param {RDD} rdd2
 * @param {RDD} rdd3 - (optional)
 * @param {RDD} rdd4 - (optional)
 * @param {boolean} preservesPartitioning - (optional)
 * @returns {RDD}
 * @private
 */
RDD.prototype.zipPartitionsMulti = function(rdd2,rdd3,rdd4,preservesPartitioning) {
    var rdd2_uw = rdd2 ? Utils.unwrapObject(rdd2) : null;
    var rdd3_uw = rdd3 ? Utils.unwrapObject(rdd3) : null;
    var rdd4_uw = rdd4 ? Utils.unwrapObject(rdd4) : null;
    var preserve = preservesPartitioning || false;
    var result = rdd4_uw ? this.getJavaObject().zipPartitions(rdd2_uw,rdd3_uw,rdd4_uw,preservesPartitioning) :
        rdd3_uw ? this.getJavaObject().zipPartitions(rdd2_uw,rdd3_uw,preservesPartitioning) :
        this.getJavaObject().zipPartitions(rdd2_uw,preservesPartitioning);
    return new RDD(result);
};

/**
 * Zips this RDD with its element indices. The ordering is first based on the partition index
 * and then the ordering of items within each partition. So the first item in the first
 * partition gets index 0, and the last item in the last partition receives the largest index.
 *
 * This is similar to Scala's zipWithIndex but it uses Long instead of Int as the index type.
 * This method needs to trigger a spark job when this RDD contains more than one partitions.
 *
 * Note that some RDDs, such as those returned by groupBy(), do not guarantee order of
 * elements in a partition. The index assigned to each element is therefore not guaranteed,
 * and may even change if the RDD is reevaluated. If a fixed ordering is required to guarantee
 * the same index assignments, you should sort the RDD with sortByKey() or save it to a file.
 * @returns {RDD}
 */
RDD.prototype.zipWithIndex = function() {
    var javaObject = this.getJavaObject().zipWithIndex();
    return new RDD(javaObject);
};

/**
 * Zips this RDD with generated unique Long ids. Items in the kth partition will get ids k, n+k,
 * 2*n+k, ..., where n is the number of partitions. So there may exist gaps, but this method
 * won't trigger a spark job, which is different from [[org.apache.spark.rdd.RDD#zipWithIndex]].
 *
 * Note that some RDDs, such as those returned by groupBy(), do not guarantee order of
 * elements in a partition. The unique ID assigned to each element is therefore not guaranteed,
 * and may even change if the RDD is reevaluated. If a fixed ordering is required to guarantee
 * the same index assignments, you should sort the RDD with sortByKey() or save it to a file.
 * @returns {RDD}
 */
RDD.prototype.zipWithUniqueId = function() {
   return new RDD(this.getJavaObject().zipWithUniqueId());
};
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Index</a></h2><h3>Classes</h3><ul><li><a href="Accumulator.html">Accumulator</a></li><li><a href="ArrayType.html">ArrayType</a></li><li><a href="BinaryType.html">BinaryType</a></li><li><a href="BooleanType.html">BooleanType</a></li><li><a href="ByteType.html">ByteType</a></li><li><a href="CalendarIntervalType.html">CalendarIntervalType</a></li><li><a href="Column.html">Column</a></li><li><a href="DataFrame.html">DataFrame</a></li><li><a href="DataFrameNaFunctions.html">DataFrameNaFunctions</a></li><li><a href="DataFrameReader.html">DataFrameReader</a></li><li><a href="DataFrameStatFunctions.html">DataFrameStatFunctions</a></li><li><a href="DataFrameWriter.html">DataFrameWriter</a></li><li><a href="DataType.html">DataType</a></li><li><a href="DataTypes.html">DataTypes</a></li><li><a href="DateType.html">DateType</a></li><li><a href="DecimalType.html">DecimalType</a></li><li><a href="DenseVector.html">DenseVector</a></li><li><a href="DoubleType.html">DoubleType</a></li><li><a href="DStream.html">DStream</a></li><li><a href="Duration.html">Duration</a></li><li><a href="FloatType.html">FloatType</a></li><li><a href="functions.html">functions</a></li><li><a href="GroupedData.html">GroupedData</a></li><li><a href="HashPartitioner.html">HashPartitioner</a></li><li><a href="IntegerType.html">IntegerType</a></li><li><a href="LabeledPoint.html">LabeledPoint</a></li><li><a href="LinearRegressionModel.html">LinearRegressionModel</a></li><li><a href="LinearRegressionWithSGD.html">LinearRegressionWithSGD</a></li><li><a href="LongType.html">LongType</a></li><li><a href="MapType.html">MapType</a></li><li><a href="Metadata.html">Metadata</a></li><li><a href="NullType.html">NullType</a></li><li><a href="NumericType.html">NumericType</a></li><li><a href="PartialResult.html">PartialResult</a></li><li><a href="Partitioner.html">Partitioner</a></li><li><a href="RangePartitioner.html">RangePartitioner</a></li><li><a href="RDD.html">RDD</a></li><li><a href="Row.html">Row</a></li><li><a href="RowFactory.html">RowFactory</a></li><li><a href="ShortType.html">ShortType</a></li><li><a href="SparkConf.html">SparkConf</a></li><li><a href="SparkContext.html">SparkContext</a></li><li><a href="SparkFiles.html">SparkFiles</a></li><li><a href="SQLContext.html">SQLContext</a></li><li><a href="SQLContext.QueryExecution.html">QueryExecution</a></li><li><a href="SQLContext.SparkPlanner.html">SparkPlanner</a></li><li><a href="SQLContext.SQLSession.html">SQLSession</a></li><li><a href="SqlDate.html">SqlDate</a></li><li><a href="SqlTimestamp.html">SqlTimestamp</a></li><li><a href="StorageLevel.html">StorageLevel</a></li><li><a href="StreamingContext.html">StreamingContext</a></li><li><a href="StringType.html">StringType</a></li><li><a href="StructField.html">StructField</a></li><li><a href="StructType.html">StructType</a></li><li><a href="Time.html">Time</a></li><li><a href="TimestampType.html">TimestampType</a></li><li><a href="Vector.html">Vector</a></li></ul>
</nav>

<br clear="both">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.2.3-dev</a> on Tue Jan 19 2016 18:02:49 GMT-0500 (EST)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
